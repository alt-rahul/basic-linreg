{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv(\"diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso, LogisticRegression\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, roc_curve, roc_auc_score\n",
    "\n",
    "X = diabetes_df.drop([\"Outcome\"], axis=1).values\n",
    "y = diabetes_df['Outcome'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=69)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "r_squard = reg.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(r_squard)\n",
    "print(\"mse: \" + str(mse) + \"\\nrmse: \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.1, 1, 10, 100]\n",
    "scores = []\n",
    "for alpha in alphas:\n",
    "    # Ridge is used to prevent overfitting \n",
    "    reg = Ridge(alpha = alpha) # shrinks coefficients towards zero while keeping all features\n",
    "    reg.fit(X_train, y_train)\n",
    "    score = reg.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso is also used for overfitting\n",
    "reg = Lasso(alpha=.2)  # Shrinking coefficients to 0, removing irrelavant features (diff from Ridge)\n",
    "reg.fit(X_train, y_train)\n",
    "socre = reg.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(max_iter=200) # is used for classification (yes/no), linear is used to actually model\n",
    "reg.fit(X_train,y_train)\n",
    "y_pred_prob = reg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corss Values Scores: [0.8046875 0.7265625 0.7421875 0.7890625 0.828125  0.75     ]\n",
      "Mean: 0.7734375\n",
      "Std: 0.03636520844731495\n",
      "CI: [0.72851562 0.82519531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=6, shuffle=True, random_state=69)\n",
    "cv_scores = cross_val_score(reg, X, y, cv=kf) # corss value score is when there are multiple r_squared calcualted to reduce bias on data split\n",
    "print(\"Corss Values Scores: \" + str(cv_scores))\n",
    "print(\"Mean: \" + str(np.mean(cv_scores)))\n",
    "print(\"Std: \" + str(np.std(cv_scores)))\n",
    "print(\"CI: \" + str(np.quantile(cv_scores, [.025, .975])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(auc) #niceee, pretty high i think "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
